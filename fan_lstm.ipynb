{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, BatchNormalization\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Parameters\n",
    "data_dir = \"./data/\"\n",
    "seed = int(time())\n",
    "random.seed(seed)\n",
    "\n",
    "num_fan_level = 4\n",
    "raw = [None] * num_fan_level\n",
    "\n",
    "train_test = 0.7\n",
    "\n",
    "# LSTM Parameters\n",
    "maxlen = 512\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility\n",
    "def split_continuous(data, tolerance=0):\n",
    "    data[\"time\"] = pd.to_datetime(data[\"time\"])\n",
    "    res = []\n",
    "    tmp = []\n",
    "    prev = data.iloc[0][0]\n",
    "    cnt = 0\n",
    "    for i in range(1,data.shape[0]):\n",
    "        if (prev+timedelta(seconds=1)) == data.iloc[i][0]:\n",
    "            tmp.append(np.array(data.iloc[i][1:3])) # PM2.5, PM10, FAN\n",
    "        elif cnt < tolerance:\n",
    "            tmp.append(np.array(data.iloc[i][1:3])) # PM2.5, PM10, FAN\n",
    "            cnt += 1\n",
    "        else:\n",
    "            if tmp != []:\n",
    "                res.append(tmp)\n",
    "            tmp = []\n",
    "            cnt = 0\n",
    "        prev = data.iloc[i][0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/2021-01-19oldFilter.csv...  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Loading ./data/2021-01-20-newFilter.csv...  Done.\n",
      "Loading ./data/2021-01-21noFan.csv...  Done.\n",
      "Loading ./data/2021-01-22noFan.csv...  Done.\n",
      "Loading ./data/2021-01-23Fan3-night.csv...  Done.\n",
      "Loading ./data/2021-01-23Fan3.csv...  Done.\n",
      "Loading ./data/2021-01-24_18.csv...  Done.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "raw = [None] * num_fan_level\n",
    "for file in os.listdir(data_dir):\n",
    "    file = os.path.join(data_dir,file)\n",
    "    data = pd.read_csv(file)\n",
    "    print(\"Loading {}...  \".format(file),end='')\n",
    "    for index in range(0,4):\n",
    "        df = data[data[\"fan\"]==index]\n",
    "        if df.shape[0] > 0:\n",
    "            res = split_continuous(df)\n",
    "            if raw[index] == None:\n",
    "                raw[index] = res\n",
    "            else:\n",
    "                raw[index].extend(res)\n",
    "        index += 1\n",
    "    print(\"Done.\")\n",
    "\n",
    "del df\n",
    "del file\n",
    "del data\n",
    "del index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "18\n",
      "7\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(raw[0]))\n",
    "print(len(raw[1]))\n",
    "print(len(raw[2]))\n",
    "print(len(raw[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3.]\n",
      "35\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 2. 2. 2. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split\n",
    "def train_test_split(raw, train_test=0.7):\n",
    "    trainX = []\n",
    "    trainY = []\n",
    "    testX = []\n",
    "    testY = []\n",
    "    \n",
    "    random.shuffle(raw[0])\n",
    "    trainX = raw[0][0:int(len(raw[0])*train_test)]\n",
    "    trainY = [0]*len(trainX)\n",
    "    testX = raw[0][int(len(raw[0])*train_test):]\n",
    "    testY = [0]*len(testX)\n",
    "    \n",
    "    for i in range(1,len(raw)):\n",
    "        random.shuffle(raw[i])\n",
    "        trainX.extend(raw[i][0:int(len(raw[i])*train_test)])\n",
    "        trainY.extend([i]*int(len(raw[i])*train_test))\n",
    "        testX.extend(raw[i][int(len(raw[i])*train_test):])\n",
    "        testY.extend([i]*(len(raw[i])-(int(len(raw[i])*train_test))))\n",
    "\n",
    "    return trainX, np.array(trainY).astype(\"float32\"), testX, np.array(testY).astype(\"float32\")\n",
    "\n",
    "trainX, trainY, testX, testY = train_test_split(raw, train_test=0.7)\n",
    "\n",
    "print(len(trainX))\n",
    "print(trainY)\n",
    "print(len(testX))\n",
    "print(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (74, 512, 2)\n",
      "Test X shape: (35, 512, 2)\n"
     ]
    }
   ],
   "source": [
    "# Data Pre-processing\n",
    "trainX = sequence.pad_sequences(trainX, maxlen=maxlen, dtype='float32')\n",
    "testX = sequence.pad_sequences(testX, maxlen=maxlen, dtype='float32')\n",
    "\n",
    "print('Train X shape:', trainX.shape)\n",
    "print('Test X shape:', testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 512, 2) (35,)\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/128\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.7224 - accuracy: 0.2432 - val_loss: 0.8038 - val_accuracy: 0.3143\n",
      "Epoch 2/128\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.1757 - val_loss: 0.5654 - val_accuracy: 0.2857\n",
      "Epoch 3/128\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3602 - accuracy: 0.1622 - val_loss: 0.3952 - val_accuracy: 0.2286\n",
      "Epoch 4/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1380 - accuracy: 0.1622 - val_loss: 0.1639 - val_accuracy: 0.1714\n",
      "Epoch 5/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -0.0493 - accuracy: 0.1622 - val_loss: -0.1310 - val_accuracy: 0.1714\n",
      "Epoch 6/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -0.3736 - accuracy: 0.1622 - val_loss: -0.5429 - val_accuracy: 0.1714\n",
      "Epoch 7/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -0.6755 - accuracy: 0.1622 - val_loss: -0.6746 - val_accuracy: 0.1714\n",
      "Epoch 8/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -0.8463 - accuracy: 0.1622 - val_loss: -0.7910 - val_accuracy: 0.1714\n",
      "Epoch 9/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -0.9912 - accuracy: 0.1622 - val_loss: -1.0059 - val_accuracy: 0.1714\n",
      "Epoch 10/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -0.9964 - accuracy: 0.1622 - val_loss: -1.0132 - val_accuracy: 0.1714\n",
      "Epoch 11/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -1.0825 - accuracy: 0.1622 - val_loss: -1.2323 - val_accuracy: 0.1714\n",
      "Epoch 12/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -1.2800 - accuracy: 0.1622 - val_loss: -1.2973 - val_accuracy: 0.1714\n",
      "Epoch 13/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -1.3977 - accuracy: 0.1622 - val_loss: -1.3218 - val_accuracy: 0.1714\n",
      "Epoch 14/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -1.3438 - accuracy: 0.1622 - val_loss: -1.4105 - val_accuracy: 0.1714\n",
      "Epoch 15/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -1.6347 - accuracy: 0.1622 - val_loss: -1.0476 - val_accuracy: 0.1714\n",
      "Epoch 16/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -1.8328 - accuracy: 0.1622 - val_loss: -1.4146 - val_accuracy: 0.1714\n",
      "Epoch 17/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -2.1805 - accuracy: 0.2162 - val_loss: -1.5569 - val_accuracy: 0.1714\n",
      "Epoch 18/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -2.1657 - accuracy: 0.2432 - val_loss: -1.6456 - val_accuracy: 0.1714\n",
      "Epoch 19/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -2.1736 - accuracy: 0.2297 - val_loss: -1.7082 - val_accuracy: 0.1714\n",
      "Epoch 20/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -2.0135 - accuracy: 0.2027 - val_loss: -1.9133 - val_accuracy: 0.1714\n",
      "Epoch 21/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -2.4903 - accuracy: 0.2568 - val_loss: -1.8121 - val_accuracy: 0.1714\n",
      "Epoch 22/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -2.4820 - accuracy: 0.2568 - val_loss: -1.8854 - val_accuracy: 0.2000\n",
      "Epoch 23/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -2.5924 - accuracy: 0.2568 - val_loss: -1.8610 - val_accuracy: 0.1714\n",
      "Epoch 24/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.1206 - accuracy: 0.3514 - val_loss: -1.9527 - val_accuracy: 0.1714\n",
      "Epoch 25/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.0600 - accuracy: 0.2838 - val_loss: -1.3283 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.2472 - accuracy: 0.3378 - val_loss: -1.3909 - val_accuracy: 0.1714\n",
      "Epoch 27/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -2.6322 - accuracy: 0.2973 - val_loss: -1.3867 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.1136 - accuracy: 0.2838 - val_loss: -2.1246 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.2034 - accuracy: 0.2568 - val_loss: -2.1766 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.2071 - accuracy: 0.2568 - val_loss: -2.2215 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.3363 - accuracy: 0.2568 - val_loss: -2.2621 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.2889 - accuracy: 0.3108 - val_loss: -1.5510 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.4869 - accuracy: 0.3108 - val_loss: -2.0453 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.3262 - accuracy: 0.2973 - val_loss: -2.4149 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.7368 - accuracy: 0.3108 - val_loss: -2.4615 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.2412 - accuracy: 0.2297 - val_loss: -2.5116 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.0911 - accuracy: 0.1757 - val_loss: -2.5397 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.2026 - accuracy: 0.1757 - val_loss: -2.6337 - val_accuracy: 0.1714\n",
      "Epoch 39/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.4068 - accuracy: 0.2432 - val_loss: -2.6360 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.0825 - accuracy: 0.1757 - val_loss: -2.7181 - val_accuracy: 0.1714\n",
      "Epoch 41/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.3979 - accuracy: 0.2027 - val_loss: -2.7688 - val_accuracy: 0.1714\n",
      "Epoch 42/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.6731 - accuracy: 0.2297 - val_loss: -2.8302 - val_accuracy: 0.1714\n",
      "Epoch 43/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.3421 - accuracy: 0.2027 - val_loss: -2.8202 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -4.0198 - accuracy: 0.2703 - val_loss: -2.8590 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -3.9135 - accuracy: 0.2027 - val_loss: -2.9225 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.6730 - accuracy: 0.3243 - val_loss: -2.9642 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -4.1721 - accuracy: 0.2432 - val_loss: -3.0023 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.9277 - accuracy: 0.2297 - val_loss: -2.0899 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -4.3388 - accuracy: 0.2973 - val_loss: -2.0696 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -4.9034 - accuracy: 0.2703 - val_loss: -2.1216 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -3.8944 - accuracy: 0.2838 - val_loss: -3.1092 - val_accuracy: 0.1143\n",
      "Epoch 52/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -4.7111 - accuracy: 0.2838 - val_loss: -3.1567 - val_accuracy: 0.1143\n",
      "Epoch 53/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.6214 - accuracy: 0.2703 - val_loss: -3.1820 - val_accuracy: 0.1143\n",
      "Epoch 54/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -4.6721 - accuracy: 0.2703 - val_loss: -3.2286 - val_accuracy: 0.1143\n",
      "Epoch 55/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -4.8353 - accuracy: 0.2568 - val_loss: -2.2624 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.7326 - accuracy: 0.2703 - val_loss: -3.3115 - val_accuracy: 0.1143\n",
      "Epoch 57/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -5.0785 - accuracy: 0.2838 - val_loss: -3.3620 - val_accuracy: 0.1143\n",
      "Epoch 58/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.6233 - accuracy: 0.2297 - val_loss: -3.4015 - val_accuracy: 0.1143\n",
      "Epoch 59/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.0291 - accuracy: 0.2432 - val_loss: -3.4519 - val_accuracy: 0.1143\n",
      "Epoch 60/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.5929 - accuracy: 0.2838 - val_loss: -3.4809 - val_accuracy: 0.1143\n",
      "Epoch 61/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.8921 - accuracy: 0.2568 - val_loss: -3.5480 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.3160 - accuracy: 0.2027 - val_loss: -3.6074 - val_accuracy: 0.1714\n",
      "Epoch 63/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -4.8813 - accuracy: 0.2432 - val_loss: -3.6165 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.0542 - accuracy: 0.2568 - val_loss: -3.6538 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -5.3672 - accuracy: 0.3108 - val_loss: -3.9363 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.2874 - accuracy: 0.2838 - val_loss: -3.7399 - val_accuracy: 0.1143\n",
      "Epoch 67/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.7432 - accuracy: 0.2838 - val_loss: -3.8134 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.1474 - accuracy: 0.3378 - val_loss: -3.8326 - val_accuracy: 0.1143\n",
      "Epoch 69/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.9362 - accuracy: 0.2838 - val_loss: -3.9274 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "10/10 [==============================] - 0s 14ms/step - loss: -4.6188 - accuracy: 0.2973 - val_loss: -2.8354 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.8743 - accuracy: 0.3378 - val_loss: -4.0286 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.0455 - accuracy: 0.2703 - val_loss: -4.3968 - val_accuracy: 0.1714\n",
      "Epoch 73/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.2288 - accuracy: 0.3378 - val_loss: -4.1449 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.4601 - accuracy: 0.2838 - val_loss: -3.0017 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -5.0299 - accuracy: 0.2973 - val_loss: -4.2649 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -6.0631 - accuracy: 0.2838 - val_loss: -4.3261 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.5745 - accuracy: 0.3243 - val_loss: -4.3576 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -5.7165 - accuracy: 0.2432 - val_loss: -4.3934 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.2826 - accuracy: 0.3378 - val_loss: -4.4178 - val_accuracy: 0.1714\n",
      "Epoch 80/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.8955 - accuracy: 0.2568 - val_loss: -4.4477 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -6.2138 - accuracy: 0.2973 - val_loss: -4.4645 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -6.7435 - accuracy: 0.3243 - val_loss: -4.5081 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.1737 - accuracy: 0.2838 - val_loss: -4.5267 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -6.8801 - accuracy: 0.3108 - val_loss: -4.5492 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -5.9680 - accuracy: 0.3514 - val_loss: -4.6388 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.8642 - accuracy: 0.3243 - val_loss: -4.6599 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.3922 - accuracy: 0.2568 - val_loss: -4.7114 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -6.4682 - accuracy: 0.2838 - val_loss: -4.7337 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -6.3049 - accuracy: 0.2838 - val_loss: -4.8034 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -7.2231 - accuracy: 0.3378 - val_loss: -5.2904 - val_accuracy: 0.1714\n",
      "Epoch 91/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.9966 - accuracy: 0.3378 - val_loss: -3.5861 - val_accuracy: 0.1714\n",
      "Epoch 92/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.3239 - accuracy: 0.3378 - val_loss: -3.6407 - val_accuracy: 0.1714\n",
      "Epoch 93/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -7.5044 - accuracy: 0.3108 - val_loss: -3.6550 - val_accuracy: 0.1714\n",
      "Epoch 94/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.6834 - accuracy: 0.3243 - val_loss: -5.5259 - val_accuracy: 0.1714\n",
      "Epoch 95/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.7263 - accuracy: 0.2568 - val_loss: -5.5670 - val_accuracy: 0.1714\n",
      "Epoch 96/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.3268 - accuracy: 0.2432 - val_loss: -3.7789 - val_accuracy: 0.1714\n",
      "Epoch 97/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.5925 - accuracy: 0.2568 - val_loss: -3.8733 - val_accuracy: 0.2000\n",
      "Epoch 98/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.8361 - accuracy: 0.3108 - val_loss: -3.9381 - val_accuracy: 0.1714\n",
      "Epoch 99/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.9283 - accuracy: 0.3243 - val_loss: -3.9687 - val_accuracy: 0.1714\n",
      "Epoch 100/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.4068 - accuracy: 0.2703 - val_loss: -4.9330 - val_accuracy: 0.1714\n",
      "Epoch 101/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -7.2363 - accuracy: 0.2838 - val_loss: -5.5635 - val_accuracy: 0.2286\n",
      "Epoch 102/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -6.5857 - accuracy: 0.2297 - val_loss: -5.5551 - val_accuracy: 0.2000\n",
      "Epoch 103/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -6.6185 - accuracy: 0.2297 - val_loss: -5.5615 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.2589 - accuracy: 0.2568 - val_loss: -5.5434 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.3787 - accuracy: 0.2838 - val_loss: -4.1369 - val_accuracy: 0.1714\n",
      "Epoch 106/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -8.5319 - accuracy: 0.3378 - val_loss: -4.3568 - val_accuracy: 0.2286\n",
      "Epoch 107/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -9.0482 - accuracy: 0.2568 - val_loss: -4.2336 - val_accuracy: 0.1714\n",
      "Epoch 108/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -9.2436 - accuracy: 0.3378 - val_loss: -5.1795 - val_accuracy: 0.1714\n",
      "Epoch 109/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -8.5027 - accuracy: 0.3108 - val_loss: -5.2244 - val_accuracy: 0.1714\n",
      "Epoch 110/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -8.5285 - accuracy: 0.2838 - val_loss: -5.3361 - val_accuracy: 0.1714\n",
      "Epoch 111/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -8.1325 - accuracy: 0.2568 - val_loss: -5.8759 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.3473 - accuracy: 0.2568 - val_loss: -5.3435 - val_accuracy: 0.1714\n",
      "Epoch 113/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -9.2908 - accuracy: 0.3514 - val_loss: -6.4675 - val_accuracy: 0.1714\n",
      "Epoch 114/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -8.1314 - accuracy: 0.3649 - val_loss: -6.5365 - val_accuracy: 0.1714\n",
      "Epoch 115/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -8.7177 - accuracy: 0.3108 - val_loss: -4.5846 - val_accuracy: 0.2000\n",
      "Epoch 116/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.7907 - accuracy: 0.3649 - val_loss: -4.9435 - val_accuracy: 0.2000\n",
      "Epoch 117/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.3465 - accuracy: 0.2973 - val_loss: -4.9181 - val_accuracy: 0.1714\n",
      "Epoch 118/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.9216 - accuracy: 0.2838 - val_loss: -5.1652 - val_accuracy: 0.1714\n",
      "Epoch 119/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -7.6765 - accuracy: 0.2973 - val_loss: -5.2508 - val_accuracy: 0.2000\n",
      "Epoch 120/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -7.5696 - accuracy: 0.3108 - val_loss: -5.2795 - val_accuracy: 0.2000\n",
      "Epoch 121/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -8.3880 - accuracy: 0.3378 - val_loss: -5.0553 - val_accuracy: 0.1714\n",
      "Epoch 122/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.7329 - accuracy: 0.3108 - val_loss: -6.3436 - val_accuracy: 0.1714\n",
      "Epoch 123/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -7.7079 - accuracy: 0.2297 - val_loss: -6.0770 - val_accuracy: 0.1714\n",
      "Epoch 124/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -8.5327 - accuracy: 0.2703 - val_loss: -5.9237 - val_accuracy: 0.2286\n",
      "Epoch 125/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -9.4464 - accuracy: 0.3108 - val_loss: -6.2647 - val_accuracy: 0.2000\n",
      "Epoch 126/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -8.9851 - accuracy: 0.3378 - val_loss: -5.1477 - val_accuracy: 0.2571\n",
      "Epoch 127/128\n",
      "10/10 [==============================] - 0s 12ms/step - loss: -9.6671 - accuracy: 0.3514 - val_loss: -5.1858 - val_accuracy: 0.2571\n",
      "Epoch 128/128\n",
      "10/10 [==============================] - 0s 13ms/step - loss: -8.4869 - accuracy: 0.3514 - val_loss: -6.4194 - val_accuracy: 0.2000\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_12 (Batc (None, 512, 2)            2048      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 16)                1216      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,281\n",
      "Trainable params: 2,257\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(trainX, trainY,\n",
    "          batch_size=batch_size,\n",
    "          epochs=128,\n",
    "          validation_data=(testX, testY))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: -6.4194 - accuracy: 0.2000\n",
      "Test score: -6.419435977935791\n",
      "Test accuracy: 0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(testX, testY,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
